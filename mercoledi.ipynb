{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PaoVale/FIA/blob/master/mercoledi.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**PREPROCESSING DEI DATI**"
      ],
      "metadata": {
        "id": "walAsB5ky2LJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Prima parte del codice consiste nel filtraggio dei dati e tutto questo lo effettuaiamo nella seguente maniera:"
      ],
      "metadata": {
        "id": "HoBYpSmaj24Z"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "inRNEiNvYUOl",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "#Caricamento del dataset\n",
        "file_path = 'Social_Media_Sentiment_Analysis.csv'\n",
        "data = pd.read_csv(file_path)\n",
        "\n",
        "#Siccome abbiamo posto l'attenzione su i tre social di maggiore interesse andiamo a filtrare i dati,i dati che andremo a stampare riguardano Facebook,Instagram e Twitter\n",
        "filtered_data = data[data['Platform'].isin(['Facebook', 'Instagram', 'Twitter'])]\n",
        "\n",
        "#Rimuoviamo anche gli eventuali valori nulli\n",
        "filtered_data_cleaned = filtered_data.dropna()\n",
        "\n",
        "#Rimuoviamo i valori duplicati basati su User, Platform e Post (post identici da stesso utente e piattaforma)\n",
        "filtered_data_cleaned = filtered_data_cleaned.drop_duplicates(subset=['User', 'Platform', 'Post'])\n",
        "\n",
        "#Verifichiamo se ci sono post senza testo (vuoti o contenenti solo spazi)\n",
        "filtered_data_cleaned = filtered_data_cleaned[filtered_data_cleaned['Post'].str.strip() != \"\"]\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Una volta filtrato il dataset scelto,possiamo passare alla pulizia cioè rimuovendo i social da tutto il dataset.\n",
        "Quindi andiamo a costruire un nuovo dataset con i dati che ci servono"
      ],
      "metadata": {
        "id": "UdfVGraClLh8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Visualizziamo il numero di post per piattaforma\n",
        "platform_counts = filtered_data_cleaned['Platform'].value_counts()\n",
        "\n",
        "#Dataset pulito:cioè andiamo a stampare i social d'interesse\n",
        "print(\"Conteggio dei post per piattaforma:\")\n",
        "print(platform_counts)\n",
        "print(\"\\nAnteprima del dataset pulito:\")\n",
        "print(filtered_data_cleaned.reset_index(drop=True).head(20))\n",
        "\n",
        "# Save the cleaned data to a CSV file\n",
        "filtered_data_cleaned.to_csv('cleaned_data.csv', index=False)\n",
        "print(\"File CSV pulito salvato con successo in: {'cleaned_data.csv'}\")"
      ],
      "metadata": {
        "id": "k88-kt0kksTe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a7c0db00-f6ae-44cf-fe6f-3c2d538a34fd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Conteggio dei post per piattaforma:\n",
            "Platform\n",
            "Instagram    107\n",
            "Facebook     101\n",
            "Twitter       88\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Anteprima del dataset pulito:\n",
            "        User   Platform                                            Post  \\\n",
            "0   User_328   Facebook          Totally disappointed, expected better.   \n",
            "1    User_13  Instagram          Totally disappointed, expected better.   \n",
            "2   User_380   Facebook                      Great content on AI today!   \n",
            "3   User_141  Instagram        Absolutely love the way they handled it.   \n",
            "4   User_126    Twitter                    Why do people overhype this?   \n",
            "5   User_115   Facebook               Neutral on this, nothing special.   \n",
            "6    User_72  Instagram               Neutral on this, nothing special.   \n",
            "7   User_378  Instagram  Machine Learning is the future, amazing stuff!   \n",
            "8    User_53   Facebook          Totally disappointed, expected better.   \n",
            "9   User_457  Instagram          Totally disappointed, expected better.   \n",
            "10  User_303    Twitter          Totally disappointed, expected better.   \n",
            "11   User_17  Instagram                      Great content on AI today!   \n",
            "12   User_16    Twitter                      Great content on AI today!   \n",
            "13   User_48   Facebook  Machine Learning is the future, amazing stuff!   \n",
            "14  User_112  Instagram    This update is frustrating and full of bugs.   \n",
            "15  User_120    Twitter   Not sure how I feel about the recent changes.   \n",
            "16  User_259    Twitter                      Great content on AI today!   \n",
            "17   User_14   Facebook        Absolutely love the way they handled it.   \n",
            "18  User_288  Instagram    This update is frustrating and full of bugs.   \n",
            "19  User_102  Instagram   Not sure how I feel about the recent changes.   \n",
            "\n",
            "             Hashtag Sentiment  Likes  Shares  Comments  \n",
            "0       #DataScience   Neutral    379      94        47  \n",
            "1            #Coding  Negative    122      95        33  \n",
            "2       #DataScience   Neutral    124      96        11  \n",
            "3            #Coding  Negative     25      61        35  \n",
            "4   #MachineLearning  Positive    342      31        10  \n",
            "5            #Coding   Neutral    463      89        21  \n",
            "6            #Coding  Negative    271      77        35  \n",
            "7            #Coding  Positive    115      90        27  \n",
            "8                #AI  Negative    326      26        29  \n",
            "9   #MachineLearning   Neutral     51      70        40  \n",
            "10      #DataScience  Positive    367      36        40  \n",
            "11               #AI  Negative     51      59        27  \n",
            "12               #AI   Neutral    348      68        25  \n",
            "13               #AI  Negative    394      83         1  \n",
            "14               #AI  Negative     70      45        47  \n",
            "15           #Coding  Negative      2      39        39  \n",
            "16               #AI   Neutral    493      33        12  \n",
            "17      #DataScience  Negative    500      65        37  \n",
            "18             #Tech  Positive    475      63        27  \n",
            "19               #AI   Neutral     80      59        24  \n",
            "File CSV pulito salvato con successo in: {'cleaned_data.csv'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Il terzo passo consiste nella Tokenizzazione: Suddividere il testo in parole o frasi (tokens) per facilitare\n",
        "l'analisi."
      ],
      "metadata": {
        "id": "QYvB3Uuumtc9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Installazione della libreria nltk che ci permette di effettuare la tokenizzazione della colonna dei Post\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "import string\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "#scarica i dati necessari per tokenizzazione e stopwords\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "# Download the missing 'punkt_tab' data package\n",
        "nltk.download('punkt_tab') # This line is added to fix the error\n",
        "\n",
        "\n",
        "# Lista di stopwords in italiano e inglese\n",
        "stop_words = set(stopwords.words('english') + stopwords.words('italian'))\n",
        "\n",
        "# Funzione per tokenizzare e rimuovere stopwords\n",
        "def preprocess_post(text):\n",
        "    # Rimuovi punteggiatura\n",
        "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
        "    # Tokenizza il testo\n",
        "    tokens = word_tokenize(text)\n",
        "    # Filtra i token, mantenendo solo quelli non presenti nelle stopwords\n",
        "    filtered_tokens = [word for word in tokens if word.lower() not in stop_words]\n",
        "    return filtered_tokens\n",
        "\n",
        "# Applica il preprocessing alla colonna 'Post'\n",
        "filtered_data_cleaned['Tokens'] = filtered_data_cleaned['Post'].apply(preprocess_post)\n",
        "\n",
        "# Visualizza un'anteprima del dataset con i token senza stopwords\n",
        "print(filtered_data_cleaned[['Post', 'Tokens']].head(10))\n"
      ],
      "metadata": {
        "id": "NpTORuGym5i0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e120989a-2d11-4992-8078-e0be4f9be131",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                              Post  \\\n",
            "0           Totally disappointed, expected better.   \n",
            "2           Totally disappointed, expected better.   \n",
            "3                       Great content on AI today!   \n",
            "4         Absolutely love the way they handled it.   \n",
            "5                     Why do people overhype this?   \n",
            "6                Neutral on this, nothing special.   \n",
            "7                Neutral on this, nothing special.   \n",
            "8   Machine Learning is the future, amazing stuff!   \n",
            "9           Totally disappointed, expected better.   \n",
            "12          Totally disappointed, expected better.   \n",
            "\n",
            "                                         Tokens  \n",
            "0     [Totally, disappointed, expected, better]  \n",
            "2     [Totally, disappointed, expected, better]  \n",
            "3                       [Great, content, today]  \n",
            "4              [Absolutely, love, way, handled]  \n",
            "5                            [people, overhype]  \n",
            "6                   [Neutral, nothing, special]  \n",
            "7                   [Neutral, nothing, special]  \n",
            "8   [Machine, Learning, future, amazing, stuff]  \n",
            "9     [Totally, disappointed, expected, better]  \n",
            "12    [Totally, disappointed, expected, better]  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Una volta effettuata la tokenizzazione,possiamo ora salvare il tutto sul file csv e quindi otteniamo:"
      ],
      "metadata": {
        "id": "ZDFvBiV3tlYZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Salva il dataset aggiornato in un nuovo file CSV\n",
        "output_file_path = 'Social_Media_Sentiment_Analysis_Tokens.csv'\n",
        "filtered_data_cleaned.to_csv(output_file_path, index=False)\n",
        "\n",
        "print(filtered_data_cleaned.reset_index(drop=True).head(20))\n",
        "print(f\"File CSV salvato con successo in: {output_file_path}\")"
      ],
      "metadata": {
        "id": "iehO1cCFP6DU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "50078780-f7cc-4189-c281-0d6e9cf0f7a8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "        User   Platform                                            Post  \\\n",
            "0   User_328   Facebook          Totally disappointed, expected better.   \n",
            "1    User_13  Instagram          Totally disappointed, expected better.   \n",
            "2   User_380   Facebook                      Great content on AI today!   \n",
            "3   User_141  Instagram        Absolutely love the way they handled it.   \n",
            "4   User_126    Twitter                    Why do people overhype this?   \n",
            "5   User_115   Facebook               Neutral on this, nothing special.   \n",
            "6    User_72  Instagram               Neutral on this, nothing special.   \n",
            "7   User_378  Instagram  Machine Learning is the future, amazing stuff!   \n",
            "8    User_53   Facebook          Totally disappointed, expected better.   \n",
            "9   User_457  Instagram          Totally disappointed, expected better.   \n",
            "10  User_303    Twitter          Totally disappointed, expected better.   \n",
            "11   User_17  Instagram                      Great content on AI today!   \n",
            "12   User_16    Twitter                      Great content on AI today!   \n",
            "13   User_48   Facebook  Machine Learning is the future, amazing stuff!   \n",
            "14  User_112  Instagram    This update is frustrating and full of bugs.   \n",
            "15  User_120    Twitter   Not sure how I feel about the recent changes.   \n",
            "16  User_259    Twitter                      Great content on AI today!   \n",
            "17   User_14   Facebook        Absolutely love the way they handled it.   \n",
            "18  User_288  Instagram    This update is frustrating and full of bugs.   \n",
            "19  User_102  Instagram   Not sure how I feel about the recent changes.   \n",
            "\n",
            "             Hashtag Sentiment  Likes  Shares  Comments  \\\n",
            "0       #DataScience   Neutral    379      94        47   \n",
            "1            #Coding  Negative    122      95        33   \n",
            "2       #DataScience   Neutral    124      96        11   \n",
            "3            #Coding  Negative     25      61        35   \n",
            "4   #MachineLearning  Positive    342      31        10   \n",
            "5            #Coding   Neutral    463      89        21   \n",
            "6            #Coding  Negative    271      77        35   \n",
            "7            #Coding  Positive    115      90        27   \n",
            "8                #AI  Negative    326      26        29   \n",
            "9   #MachineLearning   Neutral     51      70        40   \n",
            "10      #DataScience  Positive    367      36        40   \n",
            "11               #AI  Negative     51      59        27   \n",
            "12               #AI   Neutral    348      68        25   \n",
            "13               #AI  Negative    394      83         1   \n",
            "14               #AI  Negative     70      45        47   \n",
            "15           #Coding  Negative      2      39        39   \n",
            "16               #AI   Neutral    493      33        12   \n",
            "17      #DataScience  Negative    500      65        37   \n",
            "18             #Tech  Positive    475      63        27   \n",
            "19               #AI   Neutral     80      59        24   \n",
            "\n",
            "                                         Tokens  \n",
            "0     [Totally, disappointed, expected, better]  \n",
            "1     [Totally, disappointed, expected, better]  \n",
            "2                       [Great, content, today]  \n",
            "3              [Absolutely, love, way, handled]  \n",
            "4                            [people, overhype]  \n",
            "5                   [Neutral, nothing, special]  \n",
            "6                   [Neutral, nothing, special]  \n",
            "7   [Machine, Learning, future, amazing, stuff]  \n",
            "8     [Totally, disappointed, expected, better]  \n",
            "9     [Totally, disappointed, expected, better]  \n",
            "10    [Totally, disappointed, expected, better]  \n",
            "11                      [Great, content, today]  \n",
            "12                      [Great, content, today]  \n",
            "13  [Machine, Learning, future, amazing, stuff]  \n",
            "14            [update, frustrating, full, bugs]  \n",
            "15                [sure, feel, recent, changes]  \n",
            "16                      [Great, content, today]  \n",
            "17             [Absolutely, love, way, handled]  \n",
            "18            [update, frustrating, full, bugs]  \n",
            "19                [sure, feel, recent, changes]  \n",
            "File CSV salvato con successo in: Social_Media_Sentiment_Analysis_Tokens.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Classificazione del Sentiment**"
      ],
      "metadata": {
        "id": "5KqqsefvWHLS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Approccio con Vader:Libreria che ci permette di calcolare i punteggi sulla base di un approccio basato su un dizionario pre-addestrato di parole e frasi comuni, ciascuna associata a un punteggio di sentiment.                         I punteggi di VADER vengono calcolati come segue:                         Assegna a ogni parola o frase un valore compreso tra -1 (molto negativo) e +1 (molto positivo)."
      ],
      "metadata": {
        "id": "xVQeqiKxb3j8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.sentiment import SentimentIntensityAnalyzer\n",
        "import nltk\n",
        "\n",
        "# Scarica il lessico di VADER\n",
        "nltk.download('vader_lexicon')\n",
        "\n",
        "# Inizializza l'analizzatore VADER\n",
        "sia = SentimentIntensityAnalyzer()\n",
        "\n",
        "# Funzione per calcolare il sentiment\n",
        "def get_sentiment(post):\n",
        "    sentiment_score = sia.polarity_scores(post)\n",
        "    if sentiment_score['compound'] >= 0.05:\n",
        "        return 'Positive'\n",
        "    elif sentiment_score['compound'] <= -0.05:\n",
        "        return 'Negative'\n",
        "    else:\n",
        "        return 'Neutral'\n",
        "\n",
        "# Applica VADER alla colonna 'Post'\n",
        "filtered_data_cleaned['VADER_Sentiment'] = filtered_data_cleaned['Post'].apply(get_sentiment)\n",
        "\n",
        "# Visualizza i risultati\n",
        "print(\"Risultati di VADER:\")\n",
        "print(filtered_data_cleaned[['Post', 'VADER_Sentiment']].head(10))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VfTz3KxkcO3Y",
        "outputId": "434af139-3c82-46c8-d941-8043c6b83b1f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Risultati di VADER:\n",
            "                                              Post VADER_Sentiment\n",
            "0           Totally disappointed, expected better.        Negative\n",
            "2           Totally disappointed, expected better.        Negative\n",
            "3                       Great content on AI today!        Positive\n",
            "4         Absolutely love the way they handled it.        Positive\n",
            "5                     Why do people overhype this?         Neutral\n",
            "6                Neutral on this, nothing special.        Negative\n",
            "7                Neutral on this, nothing special.        Negative\n",
            "8   Machine Learning is the future, amazing stuff!        Positive\n",
            "9           Totally disappointed, expected better.        Negative\n",
            "12          Totally disappointed, expected better.        Negative\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n",
            "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "salviamo il file"
      ],
      "metadata": {
        "id": "BMNau80mvlay"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Specify the file path where you want to save the CSV\n",
        "output_file_path = 'social_media_sentiment_with_vader.csv'\n",
        "\n",
        "# Save the DataFrame to a CSV file\n",
        "filtered_data_cleaned.to_csv(output_file_path, index=False)\n",
        "\n",
        "# Print a confirmation message\n",
        "print(f\"DataFrame saved to: {output_file_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RwBevxvGvk3W",
        "outputId": "20c1fd24-37ee-4b56-89bd-bc6e23793801"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DataFrame saved to: social_media_sentiment_with_vader.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def detailed_sentiment(post):\n",
        "    sentiment_score = sia.polarity_scores(post)['compound']\n",
        "    if sentiment_score >= 0.75:\n",
        "        return 'Molto positivo'\n",
        "    elif sentiment_score >= 0.25:\n",
        "        return 'Moderatamente positivo'\n",
        "    elif -0.25 <= sentiment_score < 0.25:\n",
        "        return 'Neutro'\n",
        "    elif -0.75 <= sentiment_score < -0.25:\n",
        "        return 'Moderatamente negativo'\n",
        "    else:\n",
        "        return 'Molto negativo'\n",
        "\n",
        "# Applica la funzione al dataset\n",
        "filtered_data_cleaned['Detailed_Sentiment'] = filtered_data_cleaned['Post'].apply(detailed_sentiment)\n",
        "\n",
        "# Visualizza un'anteprima\n",
        "print(filtered_data_cleaned[['Post', 'Detailed_Sentiment']].head(10))\n"
      ],
      "metadata": {
        "id": "tddmt1S_dR-S",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "30bba714-799c-4604-f27c-48270663ed06"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                              Post      Detailed_Sentiment\n",
            "0           Totally disappointed, expected better.                  Neutro\n",
            "2           Totally disappointed, expected better.                  Neutro\n",
            "3                       Great content on AI today!  Moderatamente positivo\n",
            "4         Absolutely love the way they handled it.  Moderatamente positivo\n",
            "5                     Why do people overhype this?                  Neutro\n",
            "6                Neutral on this, nothing special.  Moderatamente negativo\n",
            "7                Neutral on this, nothing special.  Moderatamente negativo\n",
            "8   Machine Learning is the future, amazing stuff!  Moderatamente positivo\n",
            "9           Totally disappointed, expected better.                  Neutro\n",
            "12          Totally disappointed, expected better.                  Neutro\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Classificazione Sentiment: Secondo approccio: Uitlizziamo un modello di machine learning: Ok la nostra attenzione si posa sul modello Random Forest il quale utilizza un classificatore per addestrare e valutare un sentiment basato su un dataset testuale."
      ],
      "metadata": {
        "id": "AaVKkzVzc3bg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#rasforma i testi in una rappresentazione numerica basata sulla tecnica TF-IDF (Term Frequency-Inverse Document Frequency).\n",
        "#Ogni parola nel testo viene assegnata un punteggio che tiene conto della sua importanza relativa nel documento.\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "# Un classificatore basato su un insieme di alberi decisionali (forest).È utile per classificazioni non lineari e funziona bene con feature numeriche.\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "#Suddivide i dati in insiemi di addestramento e test.\n",
        "from sklearn.model_selection import train_test_split\n",
        "#Fornisce una valutazione dettagliata del modello, includendo metriche come accuratezza, precisione, recall, e F1-score.\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Rappresentazione numerica dei post:\n",
        "#Converte i testi (colonna Post) in una matrice sparsa, dove ogni riga rappresenta un post e ogni colonna rappresenta una parola.\n",
        "#Considera solo le 5000 parole più frequenti nel dataset per ridurre la complessità.\n",
        "vectorizer = TfidfVectorizer(max_features=5000)\n",
        "#Risultato: X è una matrice numerica in cui ogni riga rappresenta un post con le sue parole rappresentate da punteggi TF-IDF.\n",
        "X = vectorizer.fit_transform(filtered_data_cleaned['Post'])\n",
        "#y: Etichette target (colonna Sentiment) con i sentimenti corrispondenti.\n",
        "y = filtered_data_cleaned['Sentiment']  # Etichette (es: molto positivo, positivo, etc.)\n",
        "\n",
        "# Divido i dati in training e test:\n",
        "#Divide i dati in training set (80%) e test set (20%),\n",
        "#X_train e y_train: Dati di addestramento (testo e sentiment associato),\n",
        "#X_test e y_test: Dati di test (utilizzati per valutare il modello),\n",
        "#random_state=42: Garantisce che la suddivisione sia riproducibile.\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Addestramento del modello Random Forest:\n",
        "#RandomForestClassifier:\n",
        "#Costruisce una \"foresta\" composta da tanti alberi decisionali.\n",
        "#Ogni albero prende decisioni basate su un sottoinsieme di dati e feature.\n",
        "#Combina i risultati di tutti gli alberi (voto di maggioranza) per fare una predizione finale.\n",
        "#fit: Addestra il modello utilizzando i dati di training (X_train e y_train).\n",
        "clf = RandomForestClassifier(random_state=42)\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# Previsioni e valutazione\n",
        "#predict: Genera le previsioni del modello sul set di test (X_test).\n",
        "#Risultato: y_pred è un array contenente le etichette di sentiment previste per ogni post nel test set.\n",
        "y_pred = clf.predict(X_test)\n",
        "#classification_report: Mostra le metriche di valutazione per ciascuna classe di sentiment:\n",
        "#Precision: Quanti dei sentimenti predetti sono corretti.\n",
        "#Recall: Quanti dei sentimenti corretti sono stati predetti.\n",
        "#F1-score: Media armonica di precision e recall.\n",
        "#Accuracy: Percentuale complessiva di previsioni corrette.\n",
        "print(classification_report(y_test, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rZ4ZV2k0ibeT",
        "outputId": "a12a4057-6d75-4d4b-f4fb-b470473352ef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "    Negative       0.35      0.41      0.38        22\n",
            "     Neutral       0.41      0.48      0.44        23\n",
            "    Positive       0.29      0.13      0.18        15\n",
            "\n",
            "    accuracy                           0.37        60\n",
            "   macro avg       0.35      0.34      0.33        60\n",
            "weighted avg       0.35      0.37      0.35        60\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "7K_Ulg1mwMrw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Salvataggio dei dati del Sentiment:  questo codice salva il modello e il vettorizzatore in file separati, permettendoti di caricarli e riutilizzarli senza doverli riaddestrare ogni volta."
      ],
      "metadata": {
        "id": "pOHoQBu2uovl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "# Save the trained model\n",
        "with open('random_forest_model.pkl', 'wb') as f:  # Use 'wb' to write in binary mode\n",
        "    pickle.dump(clf, f)  # Save the trained model 'clf'\n",
        "\n",
        "# Save the vectorizer\n",
        "with open('tfidf_vectorizer.pkl', 'wb') as f:  # Use 'wb' to write in binary mode\n",
        "    pickle.dump(vectorizer, f)  # Save the 'vectorizer'\n",
        "\n",
        "\n",
        "# --- Later in your code, when you want to load the model and vectorizer ---\n",
        "\n",
        "# Carica il modello Random Forest\n",
        "with open('random_forest_model.pkl', 'rb') as f:\n",
        "    loaded_model = pickle.load(f)\n",
        "\n",
        "# Carica il vettorizzatore TF-IDF\n",
        "with open('tfidf_vectorizer.pkl', 'rb') as f:\n",
        "    loaded_vectorizer = pickle.load(f)\n",
        "\n",
        "# Ora puoi usare loaded_model e loaded_vectorizer per fare previsioni su nuovi dati."
      ],
      "metadata": {
        "id": "bNXB8L5ivS38"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Questo codice implementa una cross-validation per valutare le performance di un modello di Random Forest nella classificazione di sentimenti (ad esempio, \"positivo\", \"negativo\", \"neutrale\") all'interno di un dataset di testi. Il processo include i seguenti passaggi principali:\n",
        "\n",
        "Preprocessing dei Testi: I testi vengono trasformati in una matrice numerica utilizzando la tecnica TF-IDF (Term Frequency-Inverse Document Frequency), che calcola il \"peso\" di ogni parola nei documenti in base alla sua frequenza relativa.\n",
        "\n",
        "Creazione del Modello: Un classificatore Random Forest viene addestrato sui dati per imparare a prevedere le etichette di sentimenti. La Random Forest è un ensemble di alberi decisionali che combinano le previsioni di più alberi per migliorare l'accuratezza e ridurre il rischio di overfitting.\n",
        "\n",
        "Cross-Validation con StratifiedKFold: Per garantire una valutazione robusta, il codice utilizza StratifiedKFold per suddividere il dataset in 5 fold. Ogni fold serve sia come set di addestramento che di test, assicurando che le classi siano distribuite equamente tra i fold.\n",
        "\n",
        "Valutazione del Modello: Al termine di ogni ciclo di addestramento e test, viene prodotto un classification report che mostra dettagliate metriche di performance come precision, recall, F1-score e accuracy per ciascuna classe di sentimento, permettendo di analizzare come il modello si comporta su diversi tipi di sentimenti.\n",
        "\n"
      ],
      "metadata": {
        "id": "3ck08roHwX5E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# 1. Creazione della rappresentazione numerica dei testi usando TF-IDF\n",
        "vectorizer = TfidfVectorizer(max_features=5000)\n",
        "X = vectorizer.fit_transform(filtered_data_cleaned['Post'])\n",
        "y = filtered_data_cleaned['Sentiment']\n",
        "\n",
        "# 2. Inizializzazione del classificatore Random Forest\n",
        "clf = RandomForestClassifier(random_state=42)\n",
        "\n",
        "# 3. Creazione di StratifiedKFold per cross-validation\n",
        "kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "# 4. Cross-Validation:\n",
        "for fold, (train_index, test_index) in enumerate(kf.split(X, y), 1):\n",
        "    X_train, X_test = X[train_index], X[test_index]\n",
        "\n",
        "    # Use .iloc to access elements based on their position:\n",
        "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
        "\n",
        "    # 5. Addestramento del modello Random Forest\n",
        "    clf.fit(X_train, y_train)\n",
        "\n",
        "    # 6. Previsioni:\n",
        "    y_pred = clf.predict(X_test)\n",
        "\n",
        "    # 7. Valutazione del modello\n",
        "    print(f\"Fold {fold} - Classification Report:\")\n",
        "    print(classification_report(y_test, y_pred))\n",
        "    print(\"-\" * 80)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e5JwLe7AwZFp",
        "outputId": "d16d63b4-cf2b-4725-d94e-03515ef195c6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 1 - Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    Negative       0.39      0.33      0.36        21\n",
            "     Neutral       0.33      0.36      0.35        22\n",
            "    Positive       0.28      0.29      0.29        17\n",
            "\n",
            "    accuracy                           0.33        60\n",
            "   macro avg       0.33      0.33      0.33        60\n",
            "weighted avg       0.34      0.33      0.33        60\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "Fold 2 - Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    Negative       0.34      0.57      0.43        21\n",
            "     Neutral       0.42      0.45      0.43        22\n",
            "    Positive       0.00      0.00      0.00        16\n",
            "\n",
            "    accuracy                           0.37        59\n",
            "   macro avg       0.25      0.34      0.29        59\n",
            "weighted avg       0.28      0.37      0.31        59\n",
            "\n",
            "--------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 3 - Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    Negative       0.48      0.48      0.48        21\n",
            "     Neutral       0.56      0.86      0.68        22\n",
            "    Positive       0.25      0.06      0.10        16\n",
            "\n",
            "    accuracy                           0.51        59\n",
            "   macro avg       0.43      0.47      0.42        59\n",
            "weighted avg       0.45      0.51      0.45        59\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "Fold 4 - Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    Negative       0.36      0.24      0.29        21\n",
            "     Neutral       0.47      0.68      0.56        22\n",
            "    Positive       0.23      0.19      0.21        16\n",
            "\n",
            "    accuracy                           0.39        59\n",
            "   macro avg       0.35      0.37      0.35        59\n",
            "weighted avg       0.36      0.39      0.36        59\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "Fold 5 - Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    Negative       0.28      0.36      0.31        22\n",
            "     Neutral       0.36      0.38      0.37        21\n",
            "    Positive       0.00      0.00      0.00        16\n",
            "\n",
            "    accuracy                           0.27        59\n",
            "   macro avg       0.21      0.25      0.23        59\n",
            "weighted avg       0.23      0.27      0.25        59\n",
            "\n",
            "--------------------------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ANALISI DELLE PIATTAFORME:Questo codice analizza la distribuzione dei sentimenti (positivo, neutro, negativo) per ciascuna piattaforma sociale nel dataset, come Twitter, Facebook e Instagram. L'analisi si svolge in tre passaggi principali:\n",
        "\n",
        "Raggruppamento dei Dati: I dati vengono raggruppati per piattaforma e per tipo di sentimento (presente nella colonna \"Sentiment\" del dataset). Viene calcolato il numero di post con ciascun tipo di sentimento per ogni piattaforma.\n",
        "\n",
        "Calcolo delle Percentuali: Per ogni piattaforma, vengono calcolate le percentuali di post con sentimenti positivi, neutri e negativi, normalizzando i conteggi in modo che la somma di ogni piattaforma sia pari al 100%.\n",
        "\n",
        "Visualizzazione con Grafico a Barre: Un grafico a barre impilate mostra le percentuali di sentimenti per ciascuna piattaforma, permettendo di confrontare facilmente le opinioni espresse sui diversi social network.\n",
        "\n",
        "Questo approccio aiuta a visualizzare come i sentimenti variano tra le piattaforme sociali, fornendo un'analisi utile per comprendere le differenze nei comportamenti degli utenti su ciascun canale."
      ],
      "metadata": {
        "id": "mpNsXchC56xc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "\n",
        "# Supponiamo che tu abbia un DataFrame con i post, i sentimenti predetti e le piattaforme\n",
        "# filtered_data_cleaned è il DataFrame originale contenente il testo e le piattaforme\n",
        "# Le predizioni di sentiment sono state fatte dal modello RandomForest (ad esempio, y_pred)\n",
        "\n",
        "# Aggiungiamo le predizioni di sentiment al DataFrame\n",
        "filtered_data_cleaned['Sentiment_Predicted'] = y_pred  # y_pred è il risultato del modello\n",
        "\n",
        "# 1. Calcolare la distribuzione dei sentimenti per ciascuna piattaforma\n",
        "sentiment_distribution = filtered_data_cleaned.groupby(['Piattaforma', 'Sentiment_Predicted']).size().unstack(fill_value=0)\n",
        "\n",
        "# 2. Calcolare la percentuale per ciascun sentiment per piattaforma\n",
        "sentiment_percentage = sentiment_distribution.div(sentiment_distribution.sum(axis=1), axis=0) * 100\n",
        "\n",
        "# 3. Visualizzare la distribuzione con un grafico a barre\n",
        "plt.figure(figsize=(10, 6))\n",
        "sentiment_percentage.plot(kind='bar', stacked=True, color=['green', 'gray', 'red'], width=0.8)\n",
        "plt.title('Distribuzione del Sentiment per Piattaforma')\n",
        "plt.xlabel('Piattaforma')\n",
        "plt.ylabel('Percentuale di Post (%)')\n",
        "plt.xticks(rotation=0)\n",
        "plt.legend(title='Sentimento', labels=['Positivo', 'Neutro', 'Negativo'])\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "3CKvOiKQ5rnx"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}